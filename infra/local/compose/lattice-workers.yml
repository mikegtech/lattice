# Lattice Workers - NestJS Kafka Workers
# Run with: docker compose -f lattice-core.yml -f lattice-workers.yml up -d
#
# Workers:
#   - mail-parser: Parses raw RFC822 emails into structured format
#   - mail-chunker: Chunks parsed emails for embedding
#   - mail-embedder: Generates embeddings for chunks and stores in Postgres
#   - mail-upserter: Upserts embedding vectors to Milvus
#   - mail-extractor: Extracts text from PDF/DOCX attachments
#   - attachment-chunker: Chunks extracted attachment text for embedding
#   - mail-deleter: Handles email lifecycle deletions (vectors, postgres, storage)
#   - audit-writer: Writes audit events to Postgres (terminal consumer)

x-common-env: &common-env
  NODE_ENV: production
  LOG_LEVEL: info
  LATTICE_TEAM: platform
  LATTICE_CLOUD: local
  LATTICE_REGION: local

x-kafka-env: &kafka-env
  KAFKA_BROKERS: ${KAFKA_BROKERS:-pkc-619z3.us-east1.gcp.confluent.cloud:9092}
  KAFKA_SSL: "true"
  KAFKA_SASL_MECHANISM: plain
  KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-}
  KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-}

x-postgres-env: &postgres-env
  DATABASE_URL: postgresql://lattice:${POSTGRES_PASSWORD:-lattice_dev_password}@postgres:5432/lattice

x-datadog-env: &datadog-env
  DD_ENV: local
  DD_AGENT_HOST: ${DD_AGENT_HOST:-lattice-datadog-agent}
  DD_TRACE_AGENT_PORT: ${DD_TRACE_AGENT_PORT:-8126}
  DD_TRACE_ENABLED: ${DD_TRACE_ENABLED:-false}
  DD_DOGSTATSD_PORT: ${DD_DOGSTATSD_PORT:-8125}

x-newrelic-env: &newrelic-env
  TELEMETRY_PROVIDER: ${TELEMETRY_PROVIDER:-newrelic}
  NEW_RELIC_LICENSE_KEY: ${NEW_RELIC_LICENSE_KEY:-}
  NEW_RELIC_ENABLED: ${NEW_RELIC_ENABLED:-true}
  NEW_RELIC_LOG_LEVEL: ${NEW_RELIC_LOG_LEVEL:-info}
  NEW_RELIC_DISTRIBUTED_TRACING_ENABLED: "true"
  # Log forwarding handled by Fluent Bit (newrelic-logging.yml), not APM agent
  NEW_RELIC_APPLICATION_LOGGING_ENABLED: "true"
  NEW_RELIC_APPLICATION_LOGGING_LOCAL_DECORATING_ENABLED: "true"

x-milvus-env: &milvus-env
  MILVUS_HOST: milvus
  MILVUS_PORT: "19530"
  MILVUS_COLLECTION: email_chunks_v1
  MILVUS_CONNECT_TIMEOUT_MS: "10000"

x-storage-env: &storage-env
  MINIO_ENDPOINT: http://minio:9000
  MINIO_ACCESS_KEY: minioadmin
  MINIO_SECRET_KEY: minioadmin # pragma: allowlist secret
  STORAGE_BUCKET: lattice-mail-raw
  S3_FORCE_PATH_STYLE: "true"

services:
  # ==========================================================================
  # Mail Parser Worker
  # Consumes: lattice.mail.raw.v1
  # Produces: lattice.mail.parse.v1, lattice.mail.attachment.v1
  # ==========================================================================
  mail-parser:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-parser/Dockerfile
    container_name: lattice-mail-parser
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-parser"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *storage-env, *datadog-env, *newrelic-env]
      # Override MinIO endpoint to use IP instead of Docker hostname
      MINIO_ENDPOINT: http://100.103.47.127:9000
      # Service identity
      DD_SERVICE: lattice-worker-mail-parser
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-parser
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: parse
      # Kafka topics
      KAFKA_CLIENT_ID: mail-parser
      KAFKA_GROUP_ID: mail-parser-group
      KAFKA_TOPIC_IN: lattice.mail.raw.v1
      KAFKA_TOPIC_OUT: lattice.mail.parse.v1
      KAFKA_TOPIC_ATTACHMENT: lattice.mail.attachment.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.parse.v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3100:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Mail Chunker Worker
  # Consumes: lattice.mail.parse.v1
  # Produces: lattice.mail.chunk.v1
  # ==========================================================================
  mail-chunker:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-chunker/Dockerfile
    container_name: lattice-mail-chunker
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-chunker"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-mail-chunker
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-chunker
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: chunk
      # Kafka topics
      KAFKA_CLIENT_ID: mail-chunker
      KAFKA_GROUP_ID: mail-chunker-group
      KAFKA_TOPIC_IN: lattice.mail.parse.v1
      KAFKA_TOPIC_OUT: lattice.mail.chunk.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.chunk.v1
      # Chunking config
      CHUNK_TARGET_TOKENS: "400"
      CHUNK_OVERLAP_TOKENS: "50"
      CHUNK_MAX_TOKENS: "512"
      CHUNKING_VERSION: v1
      NORMALIZATION_VERSION: v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3101:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Mail Embedder Worker
  # Consumes: lattice.mail.chunk.v1
  # Produces: lattice.mail.embed.v1
  # ==========================================================================
  mail-embedder:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-embedder/Dockerfile
    container_name: lattice-mail-embedder
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-embedder"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-mail-embedder
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-embedder
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: embed
      # Kafka topics
      KAFKA_CLIENT_ID: mail-embedder
      KAFKA_GROUP_ID: mail-embedder-group
      KAFKA_TOPIC_IN: lattice.mail.chunk.v1
      KAFKA_TOPIC_OUT: lattice.mail.embed.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.embed.v1
      # Embedding provider config (nomic - 768 dims, 8192 token context)
      EMBEDDING_PROVIDER: nomic
      EMBEDDING_VERSION: v1
      EMBEDDING_BATCH_SIZE: "10"
      EMBEDDING_RATE_LIMIT: "100"
      EMBEDDING_TIMEOUT_MS: "30000"
      # Nomic provider (port 8001 - primary)
      NOMIC_ENDPOINT: http://dataops.trupryce.ai:8001
      NOMIC_PREFIX: "search_document: "
      # E5 provider (port 8000 - legacy fallback)
      E5_ENDPOINT: http://dataops.trupryce.ai:8000
      E5_PREFIX: "passage: "
      # OpenAI provider (for Datadog LLM observability challenge)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: text-embedding-3-small
      OPENAI_DIMENSIONS: "768"
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3102:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Mail Upserter Worker
  # Consumes: lattice.mail.embed.v1
  # Produces: lattice.mail.upsert.v1
  # ==========================================================================
  mail-upserter:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-upserter/Dockerfile
    container_name: lattice-mail-upserter
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-upserter"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-mail-upserter
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-upserter
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: upsert
      # Kafka topics
      KAFKA_CLIENT_ID: mail-upserter
      KAFKA_GROUP_ID: mail-upserter-group
      KAFKA_TOPIC_IN: lattice.mail.embed.v1
      KAFKA_TOPIC_OUT: lattice.mail.upsert.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.upsert.v1
      # Milvus config (768 dimensions to match Nomic/E5/OpenAI)
      MILVUS_HOST: milvus
      MILVUS_PORT: "19530"
      MILVUS_COLLECTION: email_chunks_v1
      MILVUS_DIM: "768"
      MILVUS_INDEX_TYPE: HNSW
      MILVUS_HNSW_M: "16"
      MILVUS_HNSW_EF_CONSTRUCTION: "256"
      MILVUS_METRIC_TYPE: COSINE
      MILVUS_BATCH_SIZE: "100"
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3103:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Mail Extractor Worker
  # Consumes: lattice.mail.attachment.v1
  # Produces: lattice.mail.attachment.extracted.v1
  # ==========================================================================
  mail-extractor:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-extractor/Dockerfile
    container_name: lattice-mail-extractor
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-extractor"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *storage-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-mail-extractor
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-extractor
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: extract
      # Kafka topics
      KAFKA_CLIENT_ID: mail-extractor
      KAFKA_GROUP_ID: mail-extractor-group
      KAFKA_TOPIC_IN: lattice.mail.attachment.v1
      KAFKA_TOPIC_OUT: lattice.mail.attachment.extracted.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.attachment.v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3106:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Attachment Chunker Worker
  # Consumes: lattice.mail.attachment.text.v1
  # Produces: lattice.mail.chunk.v1
  # ==========================================================================
  attachment-chunker:
    build:
      context: ../../..
      dockerfile: apps/workers/attachment-chunker/Dockerfile
    container_name: lattice-attachment-chunker
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-attachment-chunker"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-attachment-chunker
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-attachment-chunker
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: chunk
      # Kafka topics
      KAFKA_CLIENT_ID: attachment-chunker
      KAFKA_GROUP_ID: attachment-chunker-group
      KAFKA_TOPIC_IN: lattice.mail.attachment.text.v1
      KAFKA_TOPIC_OUT: lattice.mail.chunk.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.attachment.chunk.v1
      # Chunking config
      CHUNK_TARGET_TOKENS: "400"
      CHUNK_OVERLAP_TOKENS: "50"
      CHUNK_MAX_TOKENS: "512"
      CHUNKING_VERSION: v1
      NORMALIZATION_VERSION: v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3107:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

 # ==========================================================================
  # Mail OCR Normalizer Worker
  # Consumes: lattice.ocr.result.v1
  # Produces: lattice.mail.attachment.text.v1
  #
  # Bridge worker that converts OCR results back to mail attachment text
  # events, enabling attachment-chunker to process OCR results identically
  # to direct text extractions.
  # ==========================================================================
  mail-ocr-normalizer:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-ocr-normalizer/Dockerfile
    container_name: lattice-mail-ocr-normalizer
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-ocr-normalizer"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *storage-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-mail-ocr-normalizer
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-ocr-normalizer
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: extract
      # Kafka topics
      KAFKA_CLIENT_ID: mail-ocr-normalizer
      KAFKA_GROUP_ID: mail-ocr-normalizer-group
      KAFKA_TOPIC_IN: lattice.ocr.result.v1
      KAFKA_TOPIC_OUT: lattice.mail.attachment.text.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.ocr.v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3109:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Mail Deleter Worker
  # Consumes: lattice.mail.delete.v1
  # Produces: lattice.mail.delete.completed.v1, lattice.audit.events.v1
  # ==========================================================================
  mail-deleter:
    build:
      context: ../../..
      dockerfile: apps/workers/mail-deleter/Dockerfile
    container_name: lattice-mail-deleter
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-mail-deleter"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *milvus-env, *storage-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-mail-deleter
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-mail-deleter
      # Lattice context
      LATTICE_DOMAIN: mail
      LATTICE_STAGE: delete
      # Kafka topics
      KAFKA_CLIENT_ID: mail-deleter
      KAFKA_GROUP_ID: mail-deleter-group
      KAFKA_TOPIC_IN: lattice.mail.delete.v1
      KAFKA_TOPIC_OUT: lattice.mail.delete.completed.v1
      KAFKA_TOPIC_DLQ: lattice.dlq.mail.delete.v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3105:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

  # ==========================================================================
  # Audit Writer Worker
  # Consumes: lattice.audit.events.v1
  # Produces: none (terminal consumer)
  # ==========================================================================
  audit-writer:
    build:
      context: ../../..
      dockerfile: apps/workers/audit-writer/Dockerfile
    container_name: lattice-audit-writer
    labels:
      com.datadoghq.ad.logs: '[{"source": "nodejs", "service": "lattice-worker-audit-writer"}]'
      com.newrelic.logs: "true"
    environment:
      <<: [*common-env, *kafka-env, *postgres-env, *datadog-env, *newrelic-env]
      # Service identity
      DD_SERVICE: lattice-worker-audit-writer
      DD_VERSION: "0.1.0"
      NEW_RELIC_APP_NAME: lattice-worker-audit-writer
      # Lattice context
      LATTICE_DOMAIN: audit
      LATTICE_STAGE: audit
      # Kafka topics
      KAFKA_CLIENT_ID: audit-writer
      KAFKA_GROUP_ID: audit-writer-group
      KAFKA_TOPIC_IN: lattice.audit.events.v1
      KAFKA_TOPIC_OUT: ""
      KAFKA_TOPIC_DLQ: lattice.dlq.audit.events.v1
      # Health
      HEALTH_PORT: 3000
    ports:
      - "3104:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - lattice-network

networks:
  lattice-network:
    external: true
    name: compose_lattice-network
